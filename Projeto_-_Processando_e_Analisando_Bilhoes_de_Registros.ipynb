{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7663fd3f",
   "metadata": {},
   "source": [
    "# <center><span style=\"font-size: 42px;color: darkgreen;\">Projeto - Processando e Analisando Bilhões de Registros com Presto, Hive e AWS EMR (Elastic MapReduce)</center></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Contexto\n",
    "\n",
    "<br>\n",
    "\n",
    "No dia a dia, as empresas buscam **processar e analisar dados na maior velocidade possível**. Para atender a essa necessidade, este projeto não utiliza um `pseudo cluster`, mas sim um `multi-node cluster` (um cluster de várias máquinas).\n",
    "\n",
    "Existem diversas alternativas para construir um cluster desse tipo. Aqui, optamos por um **Ambiente em Nuvem**, que, com apenas alguns cliques, permite configurar um `multi-node cluster` capaz de processar grandes volumes de dados. Além disso, não será necessário realizar nenhuma instalação local.\n",
    "\n",
    "O **projeto** consiste em:\n",
    "\n",
    "- **1.** Montar um ambiente de processamento de dados robusto na nuvem.\n",
    "- **2.** Processar e analisar grandes quantidades de dados utilizando ferramentas distribuídas como `Presto`, `Hive` e `AWS Elastic MapReduce (EMR)`.\n",
    "- **3.** Desligar o ambiente após o término do processamento, otimizando custos e recursos.\n",
    "\n",
    "Esse fluxo proporciona eficiência e escalabilidade, atendendo às demandas das empresas modernas de Big Data.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Instruções Gerais Sobre o Projeto\n",
    "\n",
    "<br>\n",
    "\n",
    "Este projeto utiliza uma **amostra de dados** composta por **aproximadamente 6,5 milhões de registros**, extraídos de um conjunto maior contendo **2,8 bilhões de registros**.\n",
    "\n",
    "Para processar o conjunto de dados completo, será necessário dispor de **cerca de 300 GB de espaço em disco**. O procedimento para análise será idêntico, independentemente do tamanho do conjunto de dados.\n",
    "\n",
    "A amostra foi selecionada para **facilitar a execução em ambientes com recursos limitados**, mantendo a escalabilidade para processar o dataset completo quando os recursos necessários estiverem disponíveis.\n",
    "\n",
    "Portanto, o projeto será preparado pensando em processar e analisar bilhões de registros, mas, para fins de teste e validação, utilizaremos a amostra de 6,5 milhões de registros. Isso garante eficiência no desenvolvimento enquanto mantém a flexibilidade para lidar com o volume total de dados.\n",
    "\n",
    "> É necessário criar uma conta gratuita na **AWS**.\n",
    "\n",
    "Será necessário realizar **acesso remoto ao servidor AWS**. Certifique-se que nenhum firewall ou proxy na máquina ou rede tenha **restrições de acesso remoto**.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Importante\n",
    "\n",
    "Reproduzir este projeto terá um **<span style=\"font-size: 18px;color: red;\">custo associado</span>**, embora seja baixo.\n",
    "\n",
    "> Lembre-se de **finalizar** todos os serviços AWS após a conclusão do Projeto.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Explorando a AWS\n",
    "\n",
    "<br>\n",
    "\n",
    "Após **criar uma conta**, vamos explorar a líder mundial em **Computação em Nuvem**.\n",
    "\n",
    "Ao **efetuar login**, você será direcionado à **Página Inicial do Console de Serviços**. Clique em **\"Ver todos os serviços\"** para explorar a vasta gama de recursos que a AWS oferece.\n",
    "\n",
    "Um dos **serviços** disponíveis na seção **Análise de Dados** é o **EMR** (Elastic MapReduce), que será utilizado neste projeto.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Sobre a Fonte de Dados\n",
    "\n",
    "<br>\n",
    "\n",
    "No site abaixo, você encontrará uma série de arquivos CSV com **dados de corridas de táxi** na cidade de Nova York. Os dados abrangem o período de 2009 a 2024. Para este projeto, trabalharemos com uma **amostra de 6,5 milhões de registros**.\n",
    "\n",
    "- [TLC Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Importante:** O procedimento/configuração é o mesmo, independentemente de estarmos trabalhando com 6,5 milhões ou bilhões de registros.\n",
    "\n",
    "<br>\n",
    "\n",
    "Para este projeto, utilizaremos os dados de 2020. Após acessar o link, clique em `2020`, e em seguida, no arquivo CSV **`Yellow Taxi Trip Records`** do mês de **janeiro**.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Sobre o Conjunto de Dados\n",
    "\n",
    "<br>\n",
    "\n",
    "O conjunto de dados contém informações sobre **corridas de táxi** em Nova York no ano de **2020**, com aproximadamente **6,5 milhões de registros**. O arquivo contém **19 colunas**, incluindo informações como:\n",
    "\n",
    "- **Data e hora de coleta e entrega** das corridas (`tpep_pickup_datetime`, `tpep_dropoff_datetime`).\n",
    "- **Distância da viagem** e **código da tarifa** (`trip_distance`, `RatecodeID`).\n",
    "- **Detalhes sobre o pagamento**, como o valor da tarifa e gorjeta (`fare_amount`, `tip_amount`).\n",
    "- **Localizações de coleta e entrega** (`PULocationID`, `DOLocationID`).\n",
    "- **Informações adicionais** como taxas de pedágio e taxa de melhoria (`tolls_amount`, `improvement_surcharge`).\n",
    "\n",
    "Todo o processo de análise será realizado diretamente na **AWS**, utilizando a infraestrutura em nuvem. O Jupyter será utilizado apenas para escrever o passo a passo do procedimento, e não para a execução dos cálculos. A amostra de **6,5 milhões de registros** será utilizada como base para a análise, representando uma fração significativa do conjunto total.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Resumo\n",
    "\n",
    "<br>\n",
    "\n",
    "Este é um projeto de demonstração para que você veja como configurar um **cluster multi-node** e processar grandes volumes de dados. Usaremos o **cluster Hadoop** com **Amazon EMR – Elastic MapReduce** e os serviços de motor de banco de dados **Presto** e **Hive** para análise dos dados.\n",
    "\n",
    "Tudo será demonstrado passo a passo, e o ambiente será configurado nas aulas sem custo na **AWS**. Acompanhe atentamente as instruções que serão passadas durante as aulas.\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# <center><span style=\"font-size: 38px;color: darkgreen;\">Iniciando o Laboratório</center></span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# 1. Movendo os Dados Para o AWS S3\n",
    "\n",
    "<br>\n",
    "\n",
    "Este passo consiste em **armazenar os dados no S3**, o serviço de armazenamento em nuvem da **AWS**, para que possam ser acessados pelo cluster **EMR** durante o processamento.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Passos para o Armazenamento\n",
    "\n",
    "<br>\n",
    "\n",
    "- **1.1** Na **Página Inicial** da AWS, clique em **\"Ver todos os serviços\"**.  \n",
    "- **1.2** Na seção de **Armazenamento**, clique em **S3**.\n",
    "- **1.3** Após acessar o S3, será necessário clicar em **Criar um Bucket** (um repositório de arquivos):\n",
    "   - O nome do **Bucket** deve ser **único** em toda a AWS, ou seja, deve ser um nome que nunca tenha sido utilizado por nenhuma outra conta.\n",
    "   - O nome escolhido para este projeto será: **`projeto-processando-e-analisando-bilhoes-de-registros-taxis-ny`**.\n",
    "   - Deixe todas as **configurações padrão** e clique em **Criar Bucket**.\n",
    "\n",
    "- **1.4** Após a criação do Bucket, clique sobre o **Bucket** recém-criado. Na próxima página, clique em **Carregar** para começar o processo de upload dos dados.\n",
    "\n",
    "- **1.5** Na página de carregamento, **arraste e solte** o arquivo `yellow_tripdata_2020-01.parquet` para o campo indicado, e clique em **Carregar**.\n",
    "\n",
    "- **1.6** Aguarde o tempo necessário para que o arquivo seja carregado na nuvem.\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Criando um Multi Node Cluster com EMR (Amazon Elastic MapReduce)\n",
    "\n",
    "<br>\n",
    "\n",
    "Agora, vamos trabalhar com outro serviço da AWS: o **EMR (Elastic MapReduce)**. O EMR é uma plataforma que permite processar grandes volumes de dados usando frameworks como **Apache Hadoop** e **Apache Spark**.\n",
    "\n",
    "O **EMR** é a forma que a **AWS** encontrou de oferecer um cluster com **Apache Hadoop**.\n",
    "\n",
    "Neste passo, faremos com que o **S3** e o **EMR** se comuniquem, permitindo que o EMR acesse os dados armazenados no S3 para processamento distribuído.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Passos para a Integração\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.1** Na **Página Inicial** da AWS, clique em **\"Ver todos os serviços\"**.  \n",
    "- **2.2** Na seção de **Análise de Dados**, clique em **\"EMR\"**.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Criando o Cluster\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.3** Após acessar o EMR, será necessário clicar em **\"Criar um Cluster\"**:\n",
    "  - Dar nome ao projeto. (`projeto-processando-e-analisando-bilhoes-de-registros-v1`)\n",
    "  - Configurar a **Versão do Amazon EMR** para **`6.3.0`** igual ao do curso.\n",
    "  - Em **Pacote de Aplicativos**, escolha: `PrestoSQL 350`, `Hadoop 3.2.1` e `Hive 3.1.2`.\n",
    "    - Os dados serão: **processados** com o `Hadoop`, **organizados** em formato estruturado com o `Hive` e **execução** de *query SQL* com o `PrestoSQL`.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.4** No menu **Configuração do cluster**:\n",
    "    - Deixar marcado como **Grupos de Instâncias uniformes**.\n",
    "    - Em **Escolher tipo de instância do EC2** marcar a opção `m5.xlarge`.\n",
    "    \n",
    "<br> \n",
    "\n",
    "- **2.5**  No menu **Logs de cluster** deixar marcado.\n",
    "\n",
    "<br> \n",
    "  \n",
    "- **2.6**  Na **Configuração de segurança e par de chaves do EC2**:\n",
    "  - Em **Par de chaves do Amazon EC2 para o SSH do cluster**, clicar em `Navegar` e selecionar o par de chaves criado.\n",
    "  \n",
    "<br> \n",
    "\n",
    "- **2.7** Em **Perfis do Identity and Access Management (IAM)** selecionar a opção `Escolha um perfil de serviço` ou `Usado recenetemente`.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.8** Em **Perfil de instância do EC2 para o Amazon EMR** selecionar a opção: `Escolha um perfil de Instância` ou `Usado recentemente`.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.9**  Nos demais menus, manter as configurações padrão.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.10** Após concluir as configurações, clique em **\"Criar Cluster\"**. O processo de criação do cluster pode demorar de **2 a 5 minutos** para ser concluído.\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Importante**: Após o cluster ser criado, as cobranças começam a ser aplicadas no seu **cartão de crédito** conforme o uso dos recursos da AWS (instâncias EC2, armazenamento, etc.).\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Acesso Remoto ao Cluster EMR\n",
    "\n",
    "<br>\n",
    "\n",
    "Neste passo, irá ser realizado a **configuração e acesso remoto ao cluster EMR** para gerenciar e executar tarefas diretamente nele.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Visualizando Instâncias\n",
    "\n",
    "Para ver as máquinas que estão sendo usadas na criação do cluster:\n",
    "\n",
    "- Na **Página Inicial** da AWS, clique em **\"Ver todos os serviços\"**.  \n",
    "- Na seção de **Computação**, clique em **\"EC2\"**.\n",
    "- Clicar em **Instancias**.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dando Permissões na AWS\n",
    "\n",
    "#### Configurar Acesso via SSH no EC2\n",
    "\n",
    "Para conseguir a conexão via SSH pelo terminal da sua máquina **navegue** até o menu `EC2` e siga o passo a passo:\n",
    "\n",
    "<br>\n",
    "\n",
    "- No menu esquerdo **Rede e segurança** clique em `Security groups`.\n",
    "  - Das três instâncias que devem aparecer procure na coluna `Nome do grupo de segurança` e pela instância com nome de `ElasticMapReduce-master` e clique sobre id dela:\n",
    "    - Na página da instância clique em `Editar regras de entrada` e depois `Adicionar regra`:\n",
    "    - Adicione uma nova regra:\n",
    "      - **Tipo**: SSH\n",
    "      - **Porta**: 22\n",
    "      - **Origem**: Selecione My IP para permitir acesso apenas do seu IP, ou se quiser testar, use 0.0.0.0/0 (o que permite o acesso de qualquer IP, mas não recomendado para ambientes de produção).\n",
    "\n",
    "    - **Salve** as regras de entrada.\n",
    "  \n",
    "\n",
    "<br>\n",
    "\n",
    "#### Configurar Permissões no IAM\n",
    "\n",
    "Após garantir o acesso SSH ao cluster, você precisa configurar as permissões no IAM para que o cluster possa acessar o S3. Siga o passo a passo abaixo:\n",
    "\n",
    "- Na **Página Inicial da AWS**, clique em \"**Ver todos os serviços**\".\n",
    "- Na seção Segurança, identidade e conformidade, clique em IAM.\n",
    "- No menu à esquerda, clique em Funções (Roles).\n",
    "- Selecione algo como AmazonEMR-InstanceProfile-20241125T172318 (ou o nome correspondente ao Role do seu cluster EMR).\n",
    "- Clique em Adicionar Permissões → Criar política em linha.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Na lista de serviços exibida no dropdown **\"Services\"**, selecione o serviço `S3`.\n",
    "\n",
    "- Após selecionar **S3**, você verá categorias de ações. Configure as permissões marcando as seguintes opções:\n",
    "  - Expanda a seção **Lista**.\n",
    "    - Marque a opção `ListBucket`.\n",
    "  - Expanda a seção **Leitura**.\n",
    "    - Marque a opção `GetObject`.\n",
    "  - Expanda a seção **Gravação**.\n",
    "    - Marque a opção `PutObject` (para permitir gravação no bucket).\n",
    "\n",
    "- Em **Recursos**, selecione **\"Tudo\"** para simplificar o acesso durante os testes.\n",
    "\n",
    "- Clique em **Próximo**.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Dê um **nome** à política, como `politica_teste`.\n",
    "- Clique em **Salvar** para anexar a política ao IAM Role.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Conectando ao Cluster\n",
    "\n",
    "Vamos agora nos **conectar ao cluster**, para isso basta **navegar** até o menu `EMR`:\n",
    "\n",
    "- **3.1** No menu esquerdo acesse a seção **Bloquear acesso público** e clique em `Editar`:\n",
    "  - No nova página selecione `Desativar` e depois clique em `Salvar`.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3.2** No menu esquerdo clique em `Clusters`:\n",
    "  - **Importante**: o `status` deve estar como **`Aguardando`**\n",
    "  - Na seção **Gerenciamento de cluster**:\n",
    "    - Clicar em `Conectar-se ao nó primário usando SSH`.\n",
    "    - Copiar o conteúdo da chave privada.\n",
    "  \n",
    "<br>\n",
    "\n",
    "- **3.2** Acessar o diretório onde estão as **chaves** criadas na AWS usados neste projeto e abra o **terminal**:\n",
    "\n",
    "  - No terminal **colar o conteúdo copiado em 3.2** para conectar ao cluster.\n",
    "    - **IMPORTANTE**: como já está no diretório deve-se remover o `~/` antes do nome da chave.\n",
    "  - Agora que o cluster foi conectado, basta executar os comandos necessários via terminal.\n",
    "  - Digitar `clear` para limpar a tela.\n",
    "  - Digitar `screen` para visualizar LOGO.\n",
    "  - Digitar `exit` para sair.\n",
    "  \n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Trabalhando no Terminal: Configuração e Execução de Consultas\n",
    "\n",
    "<br>\n",
    "\n",
    "Neste passo, **todas as operações serão realizadas diretamente no terminal**. O objetivo é configurar permissões, criar tabelas no `Hive`, carregar dados e realizar consultas no `Presto`.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Definindo Previlégios de Acesso em Alguns Diretórios\n",
    "\n",
    "Isto é necessário para ajustar o trabalho no cluster.\n",
    "\n",
    "<br>\n",
    "\n",
    "Digitar no terminal:\n",
    "\n",
    "```code\n",
    "sudo su -c 'mkdir -p /var/log/hive/user/hadoop && chown -R hadoop /var/log/hive/user/hadoop'\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4.2 Executando o Hive\n",
    "\n",
    "<br>\n",
    "\n",
    "Digite no terminal para acessar o `Hive` se quiser:\n",
    "\n",
    "```code\n",
    "hive\n",
    "quit;\n",
    "```\n",
    "<br>\n",
    "\n",
    "Digite fora do terminal do hive para **criar tabela externa para o arquivo parquet no `Hive`** (Verificar nome do bucket criado na etapa de Armazenamento):\n",
    "\n",
    "```code\n",
    "echo \"DROP TABLE IF EXISTS tb_dados_taxis; CREATE EXTERNAL TABLE tb_dados_taxis (vendor_id INT, pickup_datetime TIMESTAMP, dropoff_datetime TIMESTAMP, passenger_count DOUBLE, trip_distance DOUBLE, rate_code_id DOUBLE, store_and_fwd_flag STRING, PULocationID INT, DOLocationID INT, payment_type INT, fare_amount DOUBLE, extra DOUBLE, mta_tax DOUBLE, tip_amount DOUBLE, tolls_amount DOUBLE, improvement_surcharge DOUBLE, total_amount DOUBLE, congestion_surcharge DOUBLE, airport_fee STRING) STORED AS PARQUET LOCATION 's3://projeto-processando-e-analisando-bilhoes-de-registros-taxis-ny/';\" | hive\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Para acessar ao terminal do `presto-cli`:\n",
    "\n",
    "```code\n",
    "presto-cli --catalog hive --schema default\n",
    "quit;\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Digite no terminal para **consulta para contar as viagens por quantidade de passageiros**:\n",
    "\n",
    "```code\n",
    "echo \"SELECT COALESCE(passenger_count, 0) AS passenger_count, count(*) FROM tb_dados_taxis GROUP BY COALESCE(passenger_count, 0);\" | presto-cli --catalog hive --schema default\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Exemplo se for digitar no **terminal do presto-cli**:\n",
    "\n",
    "```code\n",
    "SELECT COALESCE(passenger_count, 0) AS passenger_count, count(*) FROM tb_dados_taxis GROUP BY COALESCE(passenger_count, 0);\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Digite no terminal para **consulta para contar viagens por ano e quantidade de passageiros**:\n",
    "\n",
    "```code\n",
    "echo \"SELECT COALESCE(passenger_count, 0) AS passenger_count, year(COALESCE(pickup_datetime, current_timestamp)) AS trip_year, count(*) FROM tb_dados_taxis GROUP BY COALESCE(passenger_count, 0), year(COALESCE(pickup_datetime, current_timestamp));\" | presto-cli --catalog hive --schema default\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Digite no terminal para **consulta para contar viagens por ano, distância arredondada e número de passageiros**:\n",
    "\n",
    "```code\n",
    "echo \"SELECT COALESCE(passenger_count, 0) AS passenger_count, year(COALESCE(pickup_datetime, current_timestamp)) AS trip_year, round(COALESCE(trip_distance, 0)) AS rounded_distance, count(*) AS trips FROM tb_dados_taxis GROUP BY COALESCE(passenger_count, 0), year(COALESCE(pickup_datetime, current_timestamp)), round(COALESCE(trip_distance, 0)) ORDER BY trip_year, trips DESC;\" | presto-cli --catalog hive --schema default\n",
    "```\n",
    "\n",
    "Ao final da query acima digitar `:q` para finalizar.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "<br>\n",
    "\n",
    "Neste projeto, foi possível construir um **ambiente robusto e escalável** para o processamento e análise de grandes volumes de dados utilizando as ferramentas **Presto**, **Hive** e **AWS EMR**. A partir da configuração de um **multi-node cluster** e da integração com o **Amazon S3**, conseguimos explorar dados de corridas de táxi de Nova York, executando consultas otimizadas para análise de milhões de registros.\n",
    "\n",
    "#### Principais Aprendizados e Resultados\n",
    "\n",
    "- **Configuração de um cluster distribuído na AWS**: Utilizamos o EMR para criar um ambiente capaz de processar dados massivos de forma eficiente.\n",
    "- **Integração com o S3**: O armazenamento na nuvem permitiu a gestão e o acesso aos dados de maneira centralizada e segura.\n",
    "- **Execução de consultas no Presto e Hive**: Realizamos análises sobre o volume de corridas de táxi, agrupando informações por variáveis como número de passageiros e ano das corridas.\n",
    "- **Manipulação de dados no Hive**: Criamos tabelas externas para acessar os dados diretamente no formato Parquet, garantindo eficiência no armazenamento e na leitura.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Impacto do Projeto\n",
    "\n",
    "Este projeto demonstra como as tecnologias de **Big Data** podem ser utilizadas para resolver problemas reais, fornecendo insights valiosos em ambientes de alta escala. A abordagem adotada é replicável para outros casos de uso, como análise de comportamento de clientes, monitoramento de sistemas e otimização de recursos empresariais.\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Fim!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb34ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
